{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btgcVNiV3EZ0",
        "outputId": "4f60a792-e8c8-4309-b705-7d64f82dc1ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 554ms/step - accuracy: 0.5156 - loss: 0.6876 - val_accuracy: 0.5200 - val_loss: 0.7093\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 453ms/step - accuracy: 0.5989 - loss: 0.6608 - val_accuracy: 0.5950 - val_loss: 0.6560\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 612ms/step - accuracy: 0.7190 - loss: 0.5742 - val_accuracy: 0.6350 - val_loss: 0.6818\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 455ms/step - accuracy: 0.7516 - loss: 0.4962 - val_accuracy: 0.6500 - val_loss: 0.6699\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 456ms/step - accuracy: 0.8514 - loss: 0.3625 - val_accuracy: 0.7050 - val_loss: 0.6061\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 605ms/step - accuracy: 0.9206 - loss: 0.2361 - val_accuracy: 0.6700 - val_loss: 0.8830\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 569ms/step - accuracy: 0.9735 - loss: 0.0966 - val_accuracy: 0.7200 - val_loss: 0.9974\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 456ms/step - accuracy: 0.9848 - loss: 0.0528 - val_accuracy: 0.7250 - val_loss: 1.0139\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.81      0.74       103\n",
            "           1       0.74      0.60      0.66        97\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.71      0.70      0.70       200\n",
            "weighted avg       0.71      0.70      0.70       200\n",
            "\n",
            "Confusion Matrix:\n",
            "[[83 20]\n",
            " [39 58]]\n",
            "Test Accuracy: 0.705\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install textblob tensorflow\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from textblob import TextBlob\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Conv1D, MaxPooling1D, Dense, Dropout, Input, Concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from google.colab import drive\n",
        "\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path, low_memory=False,nrows=1000)\n",
        "    df.rename(columns={'comments_orig': 'comments'}, inplace=True)\n",
        "    df['clean_title'] = df['clean_title'].astype(str).str.lower()\n",
        "    df['comments'] = df['comments'].astype(str)\n",
        "    return df\n",
        "\n",
        "def get_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
        "\n",
        "def process_comments(row):\n",
        "    try:\n",
        "        comments = row['comments'].split('|__|')\n",
        "    except AttributeError:\n",
        "        return 0, 0\n",
        "    polarities, subjectivities = zip(*[get_sentiment(str(comment)) for comment in comments]) if comments else ([0], [0])\n",
        "    return np.mean(polarities), np.mean(subjectivities)\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df['comments_polarity'], df['comments_subjectivity'] = zip(*df.apply(process_comments, axis=1))\n",
        "    df['clean_title_polarity'], df['clean_title_subjectivity'] = zip(*df['clean_title'].apply(get_sentiment))\n",
        "    df['separated_comment'] = df['comments'].apply(lambda x: x.split('|__|'))\n",
        "    return df\n",
        "\n",
        "def prepare_features_and_labels(df):\n",
        "    X = df[['clean_title', 'score', 'separated_comment', 'subreddit', 'num_comments', 'upvote_ratio']]\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(df['2_way_label'].astype(str))\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42), label_encoder\n",
        "\n",
        "def build_model(max_words=10000, max_len=100):\n",
        "    text_input = Input(shape=(max_len,))\n",
        "    embedding_layer = Embedding(input_dim=max_words, output_dim=128, input_length=max_len)(text_input)\n",
        "    conv_layer = Conv1D(filters=128, kernel_size=5, activation='relu')(embedding_layer)\n",
        "    maxpool_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
        "    bilstm_layer = Bidirectional(LSTM(128, return_sequences=False))(maxpool_layer)\n",
        "    sentiment_input = Input(shape=(4,))\n",
        "    merged = Concatenate()([bilstm_layer, sentiment_input])\n",
        "    dense_layer = Dense(128, activation='relu')(merged)\n",
        "    dropout_layer = Dropout(0.5)(dense_layer)\n",
        "    output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
        "    model = Model(inputs=[text_input, sentiment_input], outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test_pad, X_test_sentiment, y_test, label_encoder):\n",
        "    y_pred = (model.predict([X_test_pad, X_test_sentiment]) > 0.5).astype(int)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"Test Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "def main():\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    file_path = \"/content/drive/My Drive/datasets/merged_cleaned_data_v34_no_photo.csv\"\n",
        "    df = load_data(file_path)\n",
        "    df = preprocess_data(df)\n",
        "    (X_train, X_test, y_train, y_test), label_encoder = prepare_features_and_labels(df)\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=10000)\n",
        "    tokenizer.fit_on_texts(X_train['clean_title'])\n",
        "    X_train_seq = tokenizer.texts_to_sequences(X_train['clean_title'])\n",
        "    X_test_seq = tokenizer.texts_to_sequences(X_test['clean_title'])\n",
        "    X_train_pad = pad_sequences(X_train_seq, maxlen=100)\n",
        "    X_test_pad = pad_sequences(X_test_seq, maxlen=100)\n",
        "    X_train_sentiment = df.loc[X_train.index, ['clean_title_polarity', 'clean_title_subjectivity', 'comments_polarity', 'comments_subjectivity']].values\n",
        "    X_test_sentiment = df.loc[X_test.index, ['clean_title_polarity', 'clean_title_subjectivity', 'comments_polarity', 'comments_subjectivity']].values\n",
        "\n",
        "    model = build_model()\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    model.fit([X_train_pad, X_train_sentiment], y_train, epochs=10, batch_size=128, validation_data=([X_test_pad, X_test_sentiment], y_test), callbacks=[early_stopping])\n",
        "    evaluate_model(model, X_test_pad, X_test_sentiment, y_test, label_encoder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}